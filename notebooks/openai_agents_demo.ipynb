{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agents Orchestration Demo\n",
    "\n",
    "Use this notebook to explore how `OpenAIAgentOrchestrator` turns the reconciliation engine into an OpenAI Agents workflow. Update the payload cells with your own GL/subledger data once you are ready to run a live reconciliation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Install dependencies from the repo root: `pip install uv` (if needed) then `uv sync`\n",
    "- Copy `.env.sample` to `.env` and set `OPENAI_API_KEY` (required) plus `GEMINI_API_KEY` or `GOOGLE_API_KEY` if you want Gemini commentary\n",
    "- Start the notebook with the project virtual environment activated so imports resolve correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Optional: load environment variables from .env when running locally.\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(\".env\")\n",
    "if env_path.exists():\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(env_path)\n",
    "else:\n",
    "    print(\"No .env file found; make sure OPENAI_API_KEY is set in your shell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recon_agent import (\n",
    "    AgentConfig,\n",
    "    GeminiConfig,\n",
    "    GeminiInsightGenerator,\n",
    "    GeminiLLM,\n",
    "    OpenAIAgentOrchestrator,\n",
    "    ReconciliationAgent,\n",
    ")\n",
    "\n",
    "reconciliation = ReconciliationAgent(\n",
    "    config=AgentConfig(materiality_threshold=10),\n",
    "    insight_generator=GeminiInsightGenerator(GeminiLLM(GeminiConfig())),\n",
    ")\n",
    "\n",
    "orchestrator = OpenAIAgentOrchestrator(reconciliation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare sample data\n",
    "\n",
    "Update the data below with your GL and subledger balances. The defaults mirror the simplified example shown in the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Reconcile inventory control account 1000 for October.\"\n",
    "\n",
    "tool_payload = {\n",
    "    \"gl_balances\": [\n",
    "        {\"account\": \"1000\", \"period\": \"2024-10\", \"amount\": 120000.0},\n",
    "    ],\n",
    "    \"subledger_balances\": [\n",
    "        {\"account\": \"1000\", \"period\": \"2024-10\", \"amount\": 118500.0},\n",
    "    ],\n",
    "    \"transactions\": [\n",
    "        {\n",
    "            \"account\": \"1000\",\n",
    "            \"booked_at\": \"2024-10-15\",\n",
    "            \"description\": \"Inventory adjustment\",\n",
    "            \"amount\": -1500.0,\n",
    "        }\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the orchestrator\n",
    "\n",
    "The supervisor role will call the reconciliation tool. The reviewer sees the resulting JSON and produces an executive summary. Running this cell requires a valid `OPENAI_API_KEY` and network access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = orchestrator.run(user_prompt, tool_payload=tool_payload)\n",
    "\n",
    "print(\"Supervisor:\\n\", reply.message)\n",
    "print(\"\\nReviewer:\\n\", reply.messages_by_role.get(\"reviewer\", \"(no reviewer message)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect structured output\n",
    "\n",
    "The raw reconciliation payload can feed downstream exports, dashboards, or audit logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(reply.tool_output, indent=2, default=str))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
